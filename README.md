Nota: La entrega final "Proyecto_ParteIII_Arancibia" la encontrarÃ¡n en la carpeta "Entregas".

---

# ğŸ· PredicciÃ³n de calidad de vino tinto con Ãrbol de DecisiÃ³n

Este proyecto fue desarrollado en marco del curso **Data Science I** de Coderhouse. Se trabajÃ³ con un dataset de vinos tintos y se aplicaron tÃ©cnicas de anÃ¡lisis exploratorio, selecciÃ³n de variables y modelado supervisado para predecir la calidad del vino en tres categorÃ­as: `baja`, `media` y `alta`.

---

## ğŸ“ Dataset

Se utilizÃ³ el dataset **Wine Quality (Red Wine)** del repositorio UCI Machine Learning, con 1144 observaciones y 13 variables fisicoquÃ­micas:

- `fixed acidity`, `volatile acidity`, `citric acid`
- `residual sugar`, `chlorides`, `sulfur dioxide` (free & total)
- `density`, `pH`, `sulphates`, `alcohol`
- `quality` (variable objetivo original: 0 a 10)

La variable `quality` fue transformada en tres clases:
- **baja:** puntuaciÃ³n â‰¤ 5
- **media:** puntuaciÃ³n = 6
- **alta:** puntuaciÃ³n â‰¥ 7

---

## ğŸ§  Objetivos del proyecto

- Formular hipÃ³tesis y explorarlas con visualizaciones
- Identificar variables relevantes
- Aplicar una tÃ©cnica de reducciÃ³n de dimensionalidad
- Entrenar un modelo de clasificaciÃ³n supervisado (Ãrbol de DecisiÃ³n)
- Evaluar su desempeÃ±o con mÃ©tricas
- Interpretar visualmente la lÃ³gica del modelo

---

## ğŸ§° Herramientas y librerÃ­as

- **Python** (Google Colab)
- **Pandas**, **NumPy**, **Seaborn**, **Matplotlib**
- `scikit-learn`: 
  - `SelectKBest`, `DecisionTreeClassifier`
  - `train_test_split`, `classification_report`, `confusion_matrix`
- `Axes3D` para grÃ¡ficos 3D

---

## ğŸ” ExploraciÃ³n y visualizaciones

Se analizaron outliers, se aplicÃ³ `df.describe()`, se identificaron correlaciones y se trabajaron hipÃ³tesis como:

1. A mayor alcohol, mayor calidad
2. A mayor acidez volÃ¡til, menor calidad
3. A mÃ¡s sulfitos, menor calidad
4. Alcohol + sulfatos podrÃ­an ser determinantes

Cada hipÃ³tesis fue acompaÃ±ada de su respectivo grÃ¡fico, anÃ¡lisis estadÃ­stico y visualizaciÃ³n.

---

## ğŸ“‰ SelecciÃ³n de variables

Se aplicÃ³ `SelectKBest` para reducir la dimensionalidad a las 6 variables mÃ¡s relevantes:

- `alcohol`, `volatile acidity`, `citric acid`, `sulphates`, `total sulfur dioxide`, `fixed acidity`

---

## ğŸŒ³ Modelado supervisado

Se entrenÃ³ un **Ãrbol de DecisiÃ³n multiclase**, sin limitar su profundidad.  
Se utilizÃ³ codificaciÃ³n manual para asignar valores numÃ©ricos a las clases (`baja = 0`, `media = 1`, `alta = 2`).

---

## ğŸ“Š Resultados del modelo

- **Accuracy:** 63%
- **Clase mÃ¡s precisa:** `baja` (F1 = 0.71)
- **ConfusiÃ³n:** principal entre `media` y `alta`
- **Matriz de confusiÃ³n** incluida
- **GrÃ¡fico 3D** de las variables mÃ¡s relevantes (`alcohol`, `sulphates`, `volatile acidity`)

---

## ğŸ“Œ Conclusiones

- `alcohol` resultÃ³ ser la variable mÃ¡s predictiva
- El modelo tiende a predecir mejor la clase `baja`
- Existen zonas de superposiciÃ³n entre `media` y `alta` que dificultan la separaciÃ³n
- El modelo es interpretable y presenta una buena base para aplicar tÃ©cnicas de mejora

---

## ğŸ‘¨â€ğŸ’» Autor

**NicolÃ¡s Arancibia**  
Curso: Data Science I â€“ Coderhouse  
GitHub: [@nicoarann](https://github.com/nicoarann)

---

